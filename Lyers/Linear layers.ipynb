{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    body {\n",
       "        --vscode-font-family: \"Comic Sans MS\";\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "    body {\n",
    "        --vscode-font-family: \"Comic Sans MS\";\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing a linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(5, 10) # in_features x out_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematics \n",
    "\n",
    "x = input  \n",
    "out = linear(x)  \n",
    "out = x * wT + b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.3216,  0.2571,  0.3775, -0.0710,  0.0808],\n",
       "         [-0.0540,  0.4249, -0.2865, -0.4096, -0.2498],\n",
       "         [-0.3567,  0.1327, -0.0067,  0.2657,  0.3833],\n",
       "         [ 0.0922, -0.3572,  0.0815, -0.4438,  0.2567],\n",
       "         [-0.2889, -0.4142,  0.3146,  0.3000, -0.2248],\n",
       "         [ 0.2340, -0.0197,  0.2359,  0.3441,  0.1129],\n",
       "         [ 0.4212, -0.0779, -0.1665,  0.3839, -0.0018],\n",
       "         [ 0.2970, -0.2355,  0.0551,  0.2381,  0.1081],\n",
       "         [ 0.4309,  0.1830,  0.3292,  0.3751, -0.1226],\n",
       "         [ 0.1609,  0.4431, -0.1526,  0.0688, -0.0522]], requires_grad=True),\n",
       " torch.Size([10, 5]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = linear.weight\n",
    "w, w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([-0.3138, -0.2444,  0.1954, -0.2383, -0.3031, -0.3036,  0.0982,  0.3253,\n",
       "         -0.0587,  0.3930], requires_grad=True),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = linear.bias\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total no of parameters\n",
    " \n",
    " parameters :  \n",
    " =  no of weights + no of bias  (if bias is True)  \n",
    " =  in_feature * out_feature + out_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60, True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculated \n",
    "par_calc = w.shape[0] * w.shape[1] + w.shape[0] # out_features x in_features + bias(out_features)\n",
    "par = sum(p.numel() for p in linear.parameters())\n",
    "par, par_calc, par == par_calc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4128,  0.5691, -1.3219,  1.1627, -0.2854],\n",
       "         [-0.4560,  1.0063, -0.1352, -0.2218,  0.7237],\n",
       "         [ 1.1138, -0.4026, -0.6635,  0.6933,  0.4720],\n",
       "         [ 0.4500, -0.4214, -0.0448,  1.2405, -0.3072],\n",
       "         [-0.1906,  0.4721, -0.2089,  0.3199,  2.3474],\n",
       "         [-1.2073,  0.1005,  0.1652, -0.7644, -0.2573],\n",
       "         [ 0.6366, -0.3258,  0.6872,  0.8834,  1.3310],\n",
       "         [-0.8105,  0.6710,  0.8526, -1.0486,  0.4852],\n",
       "         [-0.0408, -1.3647, -0.0912,  0.8115,  0.3182],\n",
       "         [-1.1366, -0.3955, -0.7339,  0.3527, -0.0524]],\n",
       "\n",
       "        [[ 1.3382, -0.8570, -1.5663, -0.0943,  0.2436],\n",
       "         [-0.6634,  1.3843,  0.2105, -0.4957,  0.1216],\n",
       "         [-0.0710,  0.4015,  0.4554,  1.3340,  0.2207],\n",
       "         [ 1.4874, -0.8041, -0.4496, -0.3118, -0.3752],\n",
       "         [ 0.2817, -0.5063,  2.2268,  1.8770, -0.4947],\n",
       "         [ 0.6496,  1.4976,  0.4285, -2.1881,  0.3168],\n",
       "         [-0.0126, -0.7871,  0.1960,  0.2699,  0.7589],\n",
       "         [ 0.3288, -2.0334,  0.6810,  0.2015, -1.3396],\n",
       "         [-0.3803, -1.7098,  1.0256,  0.3614, -2.0474],\n",
       "         [-0.1195,  0.4130, -0.8130, -0.5466,  0.0244]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 10, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-9.0477e-01, -5.1042e-02,  3.3206e-01, -1.1005e+00, -6.6096e-01,\n",
       "           -1.6226e-01,  8.9471e-01,  4.8709e-01,  2.5935e-01,  1.0083e+00],\n",
       "          [ 1.1478e-01,  1.5656e-01,  7.1094e-01, -3.6659e-01, -8.5991e-01,\n",
       "           -4.5666e-01, -2.3614e-01, -2.9092e-02, -2.8751e-01,  7.3321e-01],\n",
       "          [-1.0370e+00, -6.8729e-01,  1.1421e-01, -2.3230e-01, -5.6495e-01,\n",
       "            1.0019e-01,  9.7444e-01,  9.3041e-01,  3.3129e-01,  5.1816e-01],\n",
       "          [-6.9666e-01, -8.6612e-01,  1.9114e-01, -6.7931e-01,  1.6857e-01,\n",
       "            1.9155e-01,  8.0483e-01,  8.1787e-01,  5.4633e-01,  3.8695e-01],\n",
       "          [-4.3021e-02, -6.9116e-01,  1.3122e+00,  1.9126e-02, -9.4100e-01,\n",
       "           -3.1812e-02,  1.3446e-01,  4.7593e-01, -2.9105e-01,  5.0298e-01],\n",
       "          [ 1.9623e-01,  1.9351e-01,  3.3658e-01, -9.8836e-02, -1.1541e-01,\n",
       "           -8.4115e-01, -7.3855e-01, -2.5763e-01, -7.6143e-01,  1.7891e-01],\n",
       "          [-2.9808e-01, -1.3083e+00,  6.6538e-01, -5.7565e-02, -1.7003e-01,\n",
       "            4.6804e-01,  6.1400e-01,  9.8312e-01,  5.5037e-01,  2.3756e-01],\n",
       "          [ 5.5490e-01,  1.4843e-01,  4.7521e-01,  1.0673e-01, -5.0227e-01,\n",
       "           -6.1132e-01, -8.4074e-01, -2.2365e-01, -4.5740e-01,  3.3236e-01],\n",
       "          [-7.1787e-01, -1.2076e+00,  3.6708e-01, -4.0429e-02,  4.1717e-01,\n",
       "            7.2893e-03,  5.1348e-01,  8.5710e-01, -9.0703e-02, -1.6512e-01],\n",
       "          [-3.5617e-01, -2.7220e-01,  6.2697e-01, -4.3160e-01,  7.5818e-02,\n",
       "           -6.1947e-01, -9.1989e-02,  1.1879e-01, -7.2371e-01,  1.7390e-01]],\n",
       " \n",
       "         [[-1.5293e+00, -2.5425e-01, -3.1693e-01,  1.6807e-01, -9.1052e-01,\n",
       "           -3.4806e-01,  9.5276e-01,  8.4210e-01, -2.1976e-01,  4.4840e-01],\n",
       "          [ 3.8002e-01,  4.9189e-01,  5.2924e-01, -5.2553e-01, -7.9459e-01,\n",
       "           -5.9326e-01, -5.1459e-01, -2.9095e-01, -2.2288e-01,  8.2711e-01],\n",
       "          [-9.2710e-02, -8.0189e-01,  7.1002e-01, -8.8650e-01,  4.5035e-02,\n",
       "            2.6319e-01,  4.7292e-01,  5.7628e-01,  6.0742e-01,  5.7029e-01],\n",
       "          [-1.1767e+00, -3.1602e-01, -6.6562e-01,  1.9160e-01, -5.5037e-01,\n",
       "           -1.9539e-01,  7.4320e-01,  8.1679e-01,  2.1609e-01,  3.4274e-01],\n",
       "          [ 1.3274e-01, -1.7577e+00,  3.2197e-01, -8.0997e-01,  1.2001e+00,\n",
       "            8.8760e-01,  6.0702e-01,  1.0443e+00,  1.4678e+00,  2.9105e-02],\n",
       "          [ 2.0511e-01,  1.0511e+00, -3.0050e-01,  3.7404e-01, -1.7039e+00,\n",
       "           -7.9705e-01, -6.5671e-01, -2.9760e-01, -2.2341e-01,  9.2866e-01],\n",
       "          [-3.9596e-01, -9.3434e-01,  4.5673e-01,  1.3274e-01, -1.4071e-03,\n",
       "           -6.6307e-02,  2.2385e-01,  6.6397e-01, -1.3548e-01, -8.7135e-03],\n",
       "          [-8.0776e-01, -1.0689e+00, -6.5621e-01,  1.4062e-01,  1.0200e+00,\n",
       "           -1.0779e-01,  3.6156e-01,  8.4242e-01,  1.7483e-01, -4.7533e-01],\n",
       "          [-4.3494e-01, -8.8052e-01, -5.9140e-01, -2.6497e-01,  1.4063e+00,\n",
       "           -2.2367e-01,  4.2980e-02,  5.3618e-01,  1.8868e-01, -4.5067e-01],\n",
       "          [-4.3522e-01,  3.8824e-01,  1.6235e-01, -2.1419e-01, -8.6487e-01,\n",
       "           -7.1682e-01, -5.8787e-02,  2.0260e-02, -5.1032e-01,  6.4201e-01]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " torch.Size([2, 10, 10]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = linear(x)\n",
    "out, out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-9.0477e-01, -5.1042e-02,  3.3206e-01, -1.1005e+00, -6.6096e-01,\n",
       "           -1.6226e-01,  8.9471e-01,  4.8709e-01,  2.5935e-01,  1.0083e+00],\n",
       "          [ 1.1478e-01,  1.5656e-01,  7.1094e-01, -3.6659e-01, -8.5991e-01,\n",
       "           -4.5666e-01, -2.3614e-01, -2.9092e-02, -2.8751e-01,  7.3321e-01],\n",
       "          [-1.0370e+00, -6.8729e-01,  1.1421e-01, -2.3230e-01, -5.6495e-01,\n",
       "            1.0019e-01,  9.7444e-01,  9.3041e-01,  3.3129e-01,  5.1816e-01],\n",
       "          [-6.9666e-01, -8.6612e-01,  1.9114e-01, -6.7931e-01,  1.6857e-01,\n",
       "            1.9155e-01,  8.0483e-01,  8.1787e-01,  5.4633e-01,  3.8695e-01],\n",
       "          [-4.3021e-02, -6.9116e-01,  1.3122e+00,  1.9126e-02, -9.4100e-01,\n",
       "           -3.1812e-02,  1.3446e-01,  4.7593e-01, -2.9105e-01,  5.0298e-01],\n",
       "          [ 1.9623e-01,  1.9351e-01,  3.3658e-01, -9.8836e-02, -1.1541e-01,\n",
       "           -8.4115e-01, -7.3855e-01, -2.5763e-01, -7.6143e-01,  1.7891e-01],\n",
       "          [-2.9808e-01, -1.3083e+00,  6.6538e-01, -5.7565e-02, -1.7003e-01,\n",
       "            4.6804e-01,  6.1400e-01,  9.8312e-01,  5.5037e-01,  2.3756e-01],\n",
       "          [ 5.5490e-01,  1.4843e-01,  4.7521e-01,  1.0673e-01, -5.0227e-01,\n",
       "           -6.1132e-01, -8.4074e-01, -2.2365e-01, -4.5740e-01,  3.3236e-01],\n",
       "          [-7.1787e-01, -1.2076e+00,  3.6708e-01, -4.0429e-02,  4.1717e-01,\n",
       "            7.2893e-03,  5.1348e-01,  8.5710e-01, -9.0703e-02, -1.6512e-01],\n",
       "          [-3.5617e-01, -2.7220e-01,  6.2697e-01, -4.3160e-01,  7.5818e-02,\n",
       "           -6.1947e-01, -9.1989e-02,  1.1879e-01, -7.2371e-01,  1.7390e-01]],\n",
       " \n",
       "         [[-1.5293e+00, -2.5425e-01, -3.1693e-01,  1.6807e-01, -9.1052e-01,\n",
       "           -3.4806e-01,  9.5276e-01,  8.4210e-01, -2.1976e-01,  4.4840e-01],\n",
       "          [ 3.8002e-01,  4.9189e-01,  5.2924e-01, -5.2553e-01, -7.9459e-01,\n",
       "           -5.9326e-01, -5.1459e-01, -2.9095e-01, -2.2288e-01,  8.2711e-01],\n",
       "          [-9.2710e-02, -8.0189e-01,  7.1002e-01, -8.8650e-01,  4.5035e-02,\n",
       "            2.6319e-01,  4.7292e-01,  5.7628e-01,  6.0742e-01,  5.7029e-01],\n",
       "          [-1.1767e+00, -3.1602e-01, -6.6562e-01,  1.9160e-01, -5.5037e-01,\n",
       "           -1.9539e-01,  7.4320e-01,  8.1679e-01,  2.1609e-01,  3.4274e-01],\n",
       "          [ 1.3274e-01, -1.7577e+00,  3.2197e-01, -8.0997e-01,  1.2001e+00,\n",
       "            8.8760e-01,  6.0702e-01,  1.0443e+00,  1.4678e+00,  2.9105e-02],\n",
       "          [ 2.0511e-01,  1.0511e+00, -3.0050e-01,  3.7404e-01, -1.7039e+00,\n",
       "           -7.9705e-01, -6.5671e-01, -2.9760e-01, -2.2341e-01,  9.2866e-01],\n",
       "          [-3.9596e-01, -9.3434e-01,  4.5673e-01,  1.3274e-01, -1.4071e-03,\n",
       "           -6.6307e-02,  2.2385e-01,  6.6397e-01, -1.3548e-01, -8.7135e-03],\n",
       "          [-8.0776e-01, -1.0689e+00, -6.5621e-01,  1.4062e-01,  1.0200e+00,\n",
       "           -1.0779e-01,  3.6156e-01,  8.4242e-01,  1.7483e-01, -4.7533e-01],\n",
       "          [-4.3494e-01, -8.8052e-01, -5.9140e-01, -2.6497e-01,  1.4063e+00,\n",
       "           -2.2367e-01,  4.2980e-02,  5.3618e-01,  1.8868e-01, -4.5067e-01],\n",
       "          [-4.3522e-01,  3.8824e-01,  1.6235e-01, -2.1419e-01, -8.6487e-01,\n",
       "           -7.1682e-01, -5.8787e-02,  2.0260e-02, -5.1032e-01,  6.4201e-01]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " torch.Size([2, 10, 10]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ = x @ w.mT + b\n",
    "out_, out_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out, out_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLOPS:\n",
    "\n",
    "Floating point operations: \"*, +, -, /\"  \n",
    "Flops = no of Floating point operations per second\n",
    "\n",
    "for linear layer :  \n",
    "___\n",
    "no of \"*\":  \n",
    "= in_feature * out_feature * (rest of input dimension) [weights]  \n",
    "if input shape = (2, 10, 5), in_feature = x.shape[-1] = 5, let out_feature = 10  \n",
    "then, FLOP for * = 5 * 10 * 10 * 2 = 1000  \n",
    "___\n",
    "\n",
    "no of \"+\":  \n",
    "= (in_feature-1) * out_feature [weights] * (rest of input dimension) + out_features[bias] * (rest of input dimension) \n",
    "if input shape = (2, 10, 5), in_feature = x.shape[-1] = 5, let out_feature = 10  \n",
    "then, FLOP for * = 4 * 10 * 10 * 2 + 10 * 10 * 2 = 1000\n",
    "\n",
    "total FLOP = 2000\n",
    "total FLOP = 2 * no of \"*\" or no of \"+\" = 2 * 1000 = 2000\n",
    "\n",
    "without bias:\n",
    "if input shape = (2, 10, 5), in_feature = x.shape[-1] = 5, let out_feature = 10  \n",
    "then, FLOP for * = 4 * 10 * 10 * 2  = 800\n",
    "\n",
    "total FLOP = 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without bias\n",
    "flops =  x.numel() * w.shape[0] + x[:, :, :-1].numel()  * w.shape[0] \n",
    "flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with bias\n",
    "flops =  2 *x.numel() * w.shape[0] \n",
    "flops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
